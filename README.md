

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS
REGISTER NO: 212222210004

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 

# Explanation: 
Define the Two Prompt Types:

Write a basic Prompt: Clear, detailed, and structured prompts that give specific instructions or context to guide the model.
Based on that pattern type refined the prompt and submit that with AI tool.
Get the ouput and write the report.

Prepare Multiple Test Scenarios:
Select various scenarios such as:
Generating a creative story.
Answering a factual question.
Summarizing an article or concept.
Providing advice or recommendations.
Or Any other test scenario
For each scenario, create both a na√Øve and a basic prompt. Ensure each pair of prompts targets the same task but with different levels of structure.
Run Experiments with ChatGPT:
Input the na√Øve prompt for each scenario and record the generated response.
Then input the corresponding basic prompt and capture that response.
Repeat this process for all selected scenarios to gather a full set of results.
Evaluate Responses : 
	Compare how ChatGPT performs when given na√Øve versus basic prompts and analyze the output based on Quality,Accuracy and Depth. Also analyse does ChatGPT consistently provide better results with basic prompts? Are there scenarios where na√Øve prompts work equally well?
Deliverables:
A table comparing ChatGPT's responses to na√Øve and basic prompts across all scenarios.
Analysis of how prompt clarity impacts the quality, accuracy, and depth of ChatGPT‚Äôs outputs.
Summary of findings with insights on how to structure prompts for optimal results when using ChatGPT.


# OUTPUT

---

# üìë Study of Prompt Templating Techniques for Automated Maintenance Report Generation

---

## **1. Abstract**

This study investigates the impact of prompt templating techniques on the quality of AI-generated outputs, with a focus on automated maintenance report generation. Two types of prompts‚Äî**Na√Øve** and **Basic Structured**‚Äîwere tested across multiple scenarios such as creative storytelling, factual answering, summarization, and advice-giving. Each scenario involved both a na√Øve prompt (vague, short, and open-ended) and a structured prompt (clear, detailed, and contextual). The outputs were evaluated based on **quality, accuracy, and depth**. Results revealed that structured prompts consistently produced richer, more reliable, and professionally usable responses, especially in technical contexts like maintenance reporting. This study highlights the importance of prompt clarity and provides insights into designing effective templates for practical applications.

---

## **2. Introduction**

Artificial Intelligence (AI) models like ChatGPT are increasingly used to automate document generation, including industrial reports. However, the **effectiveness of these outputs heavily depends on prompt design**. Prompt engineering, particularly **prompt templating**, provides structured ways of framing queries so that AI models generate precise and contextually relevant outputs.

The goal of this study is to explore how different prompt styles affect output quality and to assess whether structured prompts can reliably generate **automated maintenance reports** with accuracy and depth.

---

## **3. Types of Prompts**

### **3.1 Na√Øve Prompt**

* **Definition**: Simple, vague, or open-ended input with minimal instruction.
* **Characteristics**: Short, lacks structure, often ambiguous.
* **Example**: *‚ÄúWrite a report about a pump.‚Äù*

### **3.2 Basic Structured Prompt**

* **Definition**: Clear, detailed, and structured prompt that includes context, instructions, and output format.
* **Characteristics**: Provides constraints such as word count, sections, or audience.
* **Example**: *‚ÄúGenerate a maintenance report for a centrifugal pump. Include: date, machine ID, performed maintenance, detected issues, corrective actions, and next inspection schedule. Present in a professional tone.‚Äù*

---

## **4. Methodology**

1. Define prompt types (na√Øve vs structured).
2. Select **four test scenarios**: creative story, factual Q\&A, summarization, and advice/recommendation.
3. Design na√Øve and structured prompts for each scenario.
4. Run experiments with ChatGPT, record outputs.
5. Compare responses on **quality, accuracy, and depth**.
6. Apply findings to an **automated maintenance report case study**.

---

## **5. Test Scenarios and Results**

| **Scenario**       | **Na√Øve Prompt**            | **Na√Øve Response (Shortened)**       | **Basic Structured Prompt**                                                                                           | **Structured Response (Shortened)**   | **Evaluation**                                             |
| ------------------ | --------------------------- | ------------------------------------ | --------------------------------------------------------------------------------------------------------------------- | ------------------------------------- | ---------------------------------------------------------- |
| **Creative Story** | ‚ÄúWrite a story.‚Äù            | Generic, short story, no structure.  | ‚ÄúWrite a 200-word children‚Äôs story about a robot who learns kindness. Include beginning, conflict, resolution.‚Äù       | Detailed, moral-based, complete plot. | Structured prompt produced higher-quality, engaging story. |
| **Factual Q\&A**   | ‚ÄúTell me about AI.‚Äù         | Broad, unfocused overview.           | ‚ÄúExplain Artificial Intelligence in 120 words for undergraduates. Include definition, types, one real-world example.‚Äù | Concise, accurate, structured.        | Structured prompt ensured clarity and relevance.           |
| **Summarization**  | ‚ÄúSummarize climate change.‚Äù | Missed key details, uneven coverage. | ‚ÄúSummarize climate change in 100 words covering causes, effects, and solutions.‚Äù                                      | Balanced, comprehensive summary.      | Structured prompt guided coverage of required aspects.     |
| **Advice**         | ‚ÄúGive me advice.‚Äù           | Random, vague suggestions.           | ‚ÄúProvide 5 practical tips for a college student to manage time effectively. Use bullet points.‚Äù                       | Clear, actionable, structured list.   | Structured prompt produced usable, relevant advice.        |

---

## **6. Case Study: Automated Maintenance Report**

**Na√Øve Prompt:**
*"Write a report about machine maintenance."*

**Na√Øve Response (Shortened):**
*"The machine was checked. Some issues were found. Maintenance was done. The machine is working now."*

**Structured Prompt:**
\*"Generate a detailed maintenance report for a centrifugal pump. Include:

* Date of maintenance
* Machine ID
* Type of maintenance performed
* Issues detected
* Corrective actions taken
* Next scheduled inspection
  Write in professional report format."\*

**Structured Response (Shortened):**
**Maintenance Report**

* **Date:** 04-09-2025
* **Machine ID:** CP-107
* **Performed Maintenance:** Lubricated bearings, replaced worn-out seals.
* **Issues Detected:** Minor leakage at discharge valve.
* **Corrective Actions:** Seal replaced, valve tightened.
* **Next Inspection:** Scheduled on 04-10-2025.


---

## **7. Analysis and Discussion**

* **Quality**: Structured prompts improved grammar, organization, and readability.
* **Accuracy**: Structured prompts ensured inclusion of required points (causes, effects, solutions, etc.).
* **Depth**: Na√Øve prompts gave shallow outputs, while structured ones encouraged completeness.
* **Consistency**: Structured prompts consistently delivered reliable outputs across all tasks.
* **Observation**: Na√Øve prompts only worked equally well for trivial queries (e.g., *2+2*).

---

## **8. Conclusion**

This study confirms that **prompt clarity and structure strongly influence AI-generated outputs**. Basic structured prompts consistently outperform na√Øve ones in **quality, accuracy, and depth**. For applications like **automated maintenance reporting**, structured prompts are essential to ensure reliability, consistency, and professional usability.

---

## **9. Recommendations**

* Always include **context** (who, what, where).
* Specify **format and constraints** (bullets, word limit, sections).
* Give **audience guidance** (technical, student, professional).
* Use **iterative refinement** to improve outputs.

---

## **10. Future Scope**

* Integration into **Computerized Maintenance Management Systems (CMMS)**.
* Development of **industry-specific prompt libraries**.
* Use of **feedback loops** for adaptive prompt optimization.

---



# RESULT: The prompt for the above said problem executed successfully
